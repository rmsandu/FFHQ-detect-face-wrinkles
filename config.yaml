# config.yaml
epochs: 100
batch_size: 8
learning_rate: 0.00005 # Reduced for more stable training with imbalanced data
val_percent: 0.2
test_percent: 0
amp: true
weight_decay: 0.00001 # Reduced to prevent over-regularization of rare positive class
gradient_clipping: 1.0
patience: 20
augmentation: True
loss_function:
  name: "CombinedLoss" # Options: "CombinedLoss", "BCEWithLogitsLoss"
  alpha: 0.4 # Reduced dice loss weight due to class imbalance
  gamma: 4.0 #  # Increased to focus more on hard examples
  focal_alpha: 0.9 # Class weight for Focal Loss
use_class_weights: False # Set to false to deactivate class weights
checkpoint_dir: "./checkpoints/"
image_dir: "./data/masked_face_images"
mask_dir: "./data/manual_wrinkle_masks"
wandb_project: "U-Net-Face"
wandb_entity: "ralucam-sandu"

# config.yaml
epochs: 100
batch_size: 16
learning_rate: 0.0003
val_percent: 0.2
test_percent: 0
amp: true
weight_decay: 0.05
gradient_clipping: 1.0
patience: 20
augmentation: True
loss_function:
  name: "CombinedLoss" # Options: "CombinedLoss", "BCEWithLogitsLoss"
  alpha: 1.0 # For CombinedLoss: Weight for Dice Loss
  gamma: 2.0 # For Focal Loss
  focal_alpha: 0.4 # Class weight for Focal Loss
checkpoint_dir: "./checkpoints/"
image_dir: "./data/masked_face_images"
mask_dir: "./data/manual_wrinkle_masks"
wandb_project: "U-Net-Face"
wandb_entity: "ralucam-sandu"
